{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7f0e36-857c-4688-ba10-7c5d970c1983",
   "metadata": {},
   "source": [
    "## **AIM**\n",
    "\n",
    "**Implement the “AND” gate using Perceptron Learning (self implementation).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980b5c3d-7954-4f0b-a81a-e07b085f0b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     0 | Cost: 0.6931 | W: [[0. 0.]] | b: -0.1250 | predicted value: [[0 0 0 0]] \n",
      "Iteration     5 | Cost: 0.5927 | W: [[0.08713077 0.08713077]] | b: -0.5678 | predicted value: [[0 0 0 0]] \n",
      "Iteration    10 | Cost: 0.5387 | W: [[0.23300739 0.23300739]] | b: -0.8596 | predicted value: [[0 0 0 0]] \n",
      "Iteration    15 | Cost: 0.4967 | W: [[0.38881562 0.38881562]] | b: -1.0906 | predicted value: [[0 0 0 0]] \n",
      "Iteration    20 | Cost: 0.4614 | W: [[0.5395468 0.5395468]] | b: -1.2919 | predicted value: [[0 0 0 0]] \n",
      "Iteration    25 | Cost: 0.4313 | W: [[0.68106041 0.68106041]] | b: -1.4753 | predicted value: [[0 0 0 0]] \n",
      "Iteration    30 | Cost: 0.4052 | W: [[0.81288368 0.81288368]] | b: -1.6459 | predicted value: [[0 0 0 0]] \n",
      "Iteration    35 | Cost: 0.3824 | W: [[0.93570834 0.93570834]] | b: -1.8062 | predicted value: [[0 0 0 1]] \n",
      "Iteration    40 | Cost: 0.3623 | W: [[1.05050528 1.05050528]] | b: -1.9577 | predicted value: [[0 0 0 1]] \n",
      "Iteration    45 | Cost: 0.3445 | W: [[1.15822594 1.15822594]] | b: -2.1014 | predicted value: [[0 0 0 1]] \n",
      "Iteration    50 | Cost: 0.3285 | W: [[1.25971545 1.25971545]] | b: -2.2381 | predicted value: [[0 0 0 1]] \n",
      "Iteration    55 | Cost: 0.3141 | W: [[1.35569941 1.35569941]] | b: -2.3686 | predicted value: [[0 0 0 1]] \n",
      "Iteration    60 | Cost: 0.3010 | W: [[1.44679417 1.44679417]] | b: -2.4935 | predicted value: [[0 0 0 1]] \n",
      "Iteration    65 | Cost: 0.2891 | W: [[1.53352258 1.53352258]] | b: -2.6132 | predicted value: [[0 0 0 1]] \n",
      "Iteration    70 | Cost: 0.2782 | W: [[1.61632955 1.61632955]] | b: -2.7283 | predicted value: [[0 0 0 1]] \n",
      "Iteration    75 | Cost: 0.2681 | W: [[1.6955954 1.6955954]] | b: -2.8390 | predicted value: [[0 0 0 1]] \n",
      "Iteration    80 | Cost: 0.2588 | W: [[1.77164709 1.77164709]] | b: -2.9458 | predicted value: [[0 0 0 1]] \n",
      "Iteration    85 | Cost: 0.2502 | W: [[1.84476726 1.84476726]] | b: -3.0489 | predicted value: [[0 0 0 1]] \n",
      "Iteration    90 | Cost: 0.2422 | W: [[1.91520168 1.91520168]] | b: -3.1486 | predicted value: [[0 0 0 1]] \n",
      "Iteration    95 | Cost: 0.2347 | W: [[1.9831652 1.9831652]] | b: -3.2452 | predicted value: [[0 0 0 1]] \n",
      "Iteration   100 | Cost: 0.2277 | W: [[2.04884669 2.04884669]] | b: -3.3388 | predicted value: [[0 0 0 1]] \n",
      "Iteration   105 | Cost: 0.2211 | W: [[2.11241298 2.11241298]] | b: -3.4297 | predicted value: [[0 0 0 1]] \n",
      "Iteration   110 | Cost: 0.2149 | W: [[2.17401218 2.17401218]] | b: -3.5179 | predicted value: [[0 0 0 1]] \n",
      "Iteration   115 | Cost: 0.2090 | W: [[2.2337764 2.2337764]] | b: -3.6038 | predicted value: [[0 0 0 1]] \n",
      "Iteration   120 | Cost: 0.2035 | W: [[2.29182395 2.29182395]] | b: -3.6874 | predicted value: [[0 0 0 1]] \n",
      "Iteration   125 | Cost: 0.1982 | W: [[2.34826126 2.34826126]] | b: -3.7688 | predicted value: [[0 0 0 1]] \n",
      "Iteration   130 | Cost: 0.1932 | W: [[2.40318444 2.40318444]] | b: -3.8482 | predicted value: [[0 0 0 1]] \n",
      "Iteration   135 | Cost: 0.1885 | W: [[2.45668057 2.45668057]] | b: -3.9257 | predicted value: [[0 0 0 1]] \n",
      "Iteration   140 | Cost: 0.1840 | W: [[2.50882887 2.50882887]] | b: -4.0013 | predicted value: [[0 0 0 1]] \n",
      "Iteration   145 | Cost: 0.1797 | W: [[2.55970163 2.55970163]] | b: -4.0752 | predicted value: [[0 0 0 1]] \n",
      "Iteration   150 | Cost: 0.1756 | W: [[2.60936499 2.60936499]] | b: -4.1474 | predicted value: [[0 0 0 1]] \n",
      "Iteration   155 | Cost: 0.1717 | W: [[2.65787971 2.65787971]] | b: -4.2181 | predicted value: [[0 0 0 1]] \n",
      "Iteration   160 | Cost: 0.1680 | W: [[2.70530168 2.70530168]] | b: -4.2872 | predicted value: [[0 0 0 1]] \n",
      "Iteration   165 | Cost: 0.1644 | W: [[2.75168252 2.75168252]] | b: -4.3549 | predicted value: [[0 0 0 1]] \n",
      "Iteration   170 | Cost: 0.1610 | W: [[2.79706998 2.79706998]] | b: -4.4212 | predicted value: [[0 0 0 1]] \n",
      "Iteration   175 | Cost: 0.1577 | W: [[2.84150835 2.84150835]] | b: -4.4862 | predicted value: [[0 0 0 1]] \n",
      "Iteration   180 | Cost: 0.1546 | W: [[2.88503879 2.88503879]] | b: -4.5499 | predicted value: [[0 0 0 1]] \n",
      "Iteration   185 | Cost: 0.1515 | W: [[2.92769966 2.92769966]] | b: -4.6124 | predicted value: [[0 0 0 1]] \n",
      "Iteration   190 | Cost: 0.1486 | W: [[2.96952675 2.96952675]] | b: -4.6737 | predicted value: [[0 0 0 1]] \n",
      "Iteration   195 | Cost: 0.1458 | W: [[3.01055353 3.01055353]] | b: -4.7339 | predicted value: [[0 0 0 1]] \n",
      "Iteration   200 | Cost: 0.1431 | W: [[3.05081136 3.05081136]] | b: -4.7930 | predicted value: [[0 0 0 1]] \n",
      "Iteration   205 | Cost: 0.1405 | W: [[3.09032966 3.09032966]] | b: -4.8511 | predicted value: [[0 0 0 1]] \n",
      "Iteration   210 | Cost: 0.1379 | W: [[3.12913609 3.12913609]] | b: -4.9081 | predicted value: [[0 0 0 1]] \n",
      "Iteration   215 | Cost: 0.1355 | W: [[3.16725669 3.16725669]] | b: -4.9642 | predicted value: [[0 0 0 1]] \n",
      "Iteration   220 | Cost: 0.1332 | W: [[3.20471602 3.20471602]] | b: -5.0194 | predicted value: [[0 0 0 1]] \n",
      "Iteration   225 | Cost: 0.1309 | W: [[3.24153723 3.24153723]] | b: -5.0736 | predicted value: [[0 0 0 1]] \n",
      "Iteration   230 | Cost: 0.1287 | W: [[3.27774225 3.27774225]] | b: -5.1269 | predicted value: [[0 0 0 1]] \n",
      "Iteration   235 | Cost: 0.1266 | W: [[3.31335181 3.31335181]] | b: -5.1794 | predicted value: [[0 0 0 1]] \n",
      "Iteration   240 | Cost: 0.1245 | W: [[3.34838557 3.34838557]] | b: -5.2311 | predicted value: [[0 0 0 1]] \n",
      "Iteration   245 | Cost: 0.1225 | W: [[3.38286216 3.38286216]] | b: -5.2819 | predicted value: [[0 0 0 1]] \n",
      "Iteration   250 | Cost: 0.1206 | W: [[3.41679931 3.41679931]] | b: -5.3320 | predicted value: [[0 0 0 1]] \n",
      "Iteration   255 | Cost: 0.1187 | W: [[3.45021385 3.45021385]] | b: -5.3814 | predicted value: [[0 0 0 1]] \n",
      "Iteration   260 | Cost: 0.1169 | W: [[3.48312182 3.48312182]] | b: -5.4300 | predicted value: [[0 0 0 1]] \n",
      "Iteration   265 | Cost: 0.1151 | W: [[3.51553848 3.51553848]] | b: -5.4779 | predicted value: [[0 0 0 1]] \n",
      "Iteration   270 | Cost: 0.1134 | W: [[3.5474784 3.5474784]] | b: -5.5251 | predicted value: [[0 0 0 1]] \n",
      "Iteration   275 | Cost: 0.1117 | W: [[3.57895548 3.57895548]] | b: -5.5716 | predicted value: [[0 0 0 1]] \n",
      "Iteration   280 | Cost: 0.1101 | W: [[3.60998299 3.60998299]] | b: -5.6175 | predicted value: [[0 0 0 1]] \n",
      "Iteration   285 | Cost: 0.1085 | W: [[3.64057363 3.64057363]] | b: -5.6628 | predicted value: [[0 0 0 1]] \n",
      "Iteration   290 | Cost: 0.1070 | W: [[3.67073955 3.67073955]] | b: -5.7074 | predicted value: [[0 0 0 1]] \n",
      "Iteration   295 | Cost: 0.1055 | W: [[3.70049238 3.70049238]] | b: -5.7514 | predicted value: [[0 0 0 1]] \n",
      "Iteration   300 | Cost: 0.1041 | W: [[3.72984325 3.72984325]] | b: -5.7949 | predicted value: [[0 0 0 1]] \n",
      "Iteration   305 | Cost: 0.1027 | W: [[3.75880287 3.75880287]] | b: -5.8378 | predicted value: [[0 0 0 1]] \n",
      "Iteration   310 | Cost: 0.1013 | W: [[3.78738148 3.78738148]] | b: -5.8801 | predicted value: [[0 0 0 1]] \n",
      "Iteration   315 | Cost: 0.0999 | W: [[3.81558893 3.81558893]] | b: -5.9219 | predicted value: [[0 0 0 1]] \n",
      "Iteration   320 | Cost: 0.0986 | W: [[3.84343469 3.84343469]] | b: -5.9632 | predicted value: [[0 0 0 1]] \n",
      "Iteration   325 | Cost: 0.0974 | W: [[3.87092783 3.87092783]] | b: -6.0040 | predicted value: [[0 0 0 1]] \n",
      "Iteration   330 | Cost: 0.0961 | W: [[3.89807712 3.89807712]] | b: -6.0442 | predicted value: [[0 0 0 1]] \n",
      "Iteration   335 | Cost: 0.0949 | W: [[3.92489097 3.92489097]] | b: -6.0840 | predicted value: [[0 0 0 1]] \n",
      "Iteration   340 | Cost: 0.0937 | W: [[3.95137749 3.95137749]] | b: -6.1233 | predicted value: [[0 0 0 1]] \n",
      "Iteration   345 | Cost: 0.0926 | W: [[3.9775445 3.9775445]] | b: -6.1621 | predicted value: [[0 0 0 1]] \n",
      "Iteration   350 | Cost: 0.0914 | W: [[4.00339952 4.00339952]] | b: -6.2005 | predicted value: [[0 0 0 1]] \n",
      "Iteration   355 | Cost: 0.0903 | W: [[4.02894982 4.02894982]] | b: -6.2384 | predicted value: [[0 0 0 1]] \n",
      "Iteration   360 | Cost: 0.0893 | W: [[4.05420242 4.05420242]] | b: -6.2759 | predicted value: [[0 0 0 1]] \n",
      "Iteration   365 | Cost: 0.0882 | W: [[4.07916407 4.07916407]] | b: -6.3130 | predicted value: [[0 0 0 1]] \n",
      "Iteration   370 | Cost: 0.0872 | W: [[4.10384131 4.10384131]] | b: -6.3496 | predicted value: [[0 0 0 1]] \n",
      "Iteration   375 | Cost: 0.0862 | W: [[4.12824047 4.12824047]] | b: -6.3859 | predicted value: [[0 0 0 1]] \n",
      "Iteration   380 | Cost: 0.0852 | W: [[4.15236764 4.15236764]] | b: -6.4217 | predicted value: [[0 0 0 1]] \n",
      "Iteration   385 | Cost: 0.0842 | W: [[4.17622873 4.17622873]] | b: -6.4572 | predicted value: [[0 0 0 1]] \n",
      "Iteration   390 | Cost: 0.0833 | W: [[4.19982945 4.19982945]] | b: -6.4922 | predicted value: [[0 0 0 1]] \n",
      "Iteration   395 | Cost: 0.0824 | W: [[4.22317533 4.22317533]] | b: -6.5269 | predicted value: [[0 0 0 1]] \n",
      "Iteration   400 | Cost: 0.0815 | W: [[4.24627173 4.24627173]] | b: -6.5613 | predicted value: [[0 0 0 1]] \n",
      "Iteration   405 | Cost: 0.0806 | W: [[4.26912383 4.26912383]] | b: -6.5952 | predicted value: [[0 0 0 1]] \n",
      "Iteration   410 | Cost: 0.0797 | W: [[4.29173665 4.29173665]] | b: -6.6288 | predicted value: [[0 0 0 1]] \n",
      "Iteration   415 | Cost: 0.0789 | W: [[4.31411507 4.31411507]] | b: -6.6621 | predicted value: [[0 0 0 1]] \n",
      "Iteration   420 | Cost: 0.0780 | W: [[4.3362638 4.3362638]] | b: -6.6951 | predicted value: [[0 0 0 1]] \n",
      "Iteration   425 | Cost: 0.0772 | W: [[4.35818744 4.35818744]] | b: -6.7277 | predicted value: [[0 0 0 1]] \n",
      "Iteration   430 | Cost: 0.0764 | W: [[4.37989041 4.37989041]] | b: -6.7600 | predicted value: [[0 0 0 1]] \n",
      "Iteration   435 | Cost: 0.0757 | W: [[4.40137704 4.40137704]] | b: -6.7919 | predicted value: [[0 0 0 1]] \n",
      "Iteration   440 | Cost: 0.0749 | W: [[4.42265151 4.42265151]] | b: -6.8236 | predicted value: [[0 0 0 1]] \n",
      "Iteration   445 | Cost: 0.0741 | W: [[4.44371789 4.44371789]] | b: -6.8549 | predicted value: [[0 0 0 1]] \n",
      "Iteration   450 | Cost: 0.0734 | W: [[4.46458013 4.46458013]] | b: -6.8860 | predicted value: [[0 0 0 1]] \n",
      "Iteration   455 | Cost: 0.0727 | W: [[4.48524207 4.48524207]] | b: -6.9167 | predicted value: [[0 0 0 1]] \n",
      "Iteration   460 | Cost: 0.0720 | W: [[4.50570745 4.50570745]] | b: -6.9472 | predicted value: [[0 0 0 1]] \n",
      "Iteration   465 | Cost: 0.0713 | W: [[4.52597989 4.52597989]] | b: -6.9774 | predicted value: [[0 0 0 1]] \n",
      "Iteration   470 | Cost: 0.0706 | W: [[4.54606292 4.54606292]] | b: -7.0073 | predicted value: [[0 0 0 1]] \n",
      "Iteration   475 | Cost: 0.0699 | W: [[4.56595998 4.56595998]] | b: -7.0369 | predicted value: [[0 0 0 1]] \n",
      "Iteration   480 | Cost: 0.0693 | W: [[4.58567441 4.58567441]] | b: -7.0662 | predicted value: [[0 0 0 1]] \n",
      "Iteration   485 | Cost: 0.0686 | W: [[4.60520945 4.60520945]] | b: -7.0953 | predicted value: [[0 0 0 1]] \n",
      "Iteration   490 | Cost: 0.0680 | W: [[4.62456828 4.62456828]] | b: -7.1242 | predicted value: [[0 0 0 1]] \n",
      "Iteration   495 | Cost: 0.0674 | W: [[4.64375398 4.64375398]] | b: -7.1527 | predicted value: [[0 0 0 1]] \n",
      "Iteration   500 | Cost: 0.0668 | W: [[4.66276955 4.66276955]] | b: -7.1811 | predicted value: [[0 0 0 1]] \n",
      "Iteration   505 | Cost: 0.0662 | W: [[4.68161792 4.68161792]] | b: -7.2091 | predicted value: [[0 0 0 1]] \n",
      "Iteration   510 | Cost: 0.0656 | W: [[4.70030194 4.70030194]] | b: -7.2370 | predicted value: [[0 0 0 1]] \n",
      "Iteration   515 | Cost: 0.0650 | W: [[4.71882439 4.71882439]] | b: -7.2646 | predicted value: [[0 0 0 1]] \n",
      "Iteration   520 | Cost: 0.0644 | W: [[4.73718798 4.73718798]] | b: -7.2919 | predicted value: [[0 0 0 1]] \n",
      "Iteration   525 | Cost: 0.0639 | W: [[4.75539536 4.75539536]] | b: -7.3191 | predicted value: [[0 0 0 1]] \n",
      "Iteration   530 | Cost: 0.0633 | W: [[4.77344909 4.77344909]] | b: -7.3460 | predicted value: [[0 0 0 1]] \n",
      "Iteration   535 | Cost: 0.0628 | W: [[4.79135169 4.79135169]] | b: -7.3727 | predicted value: [[0 0 0 1]] \n",
      "Iteration   540 | Cost: 0.0622 | W: [[4.80910563 4.80910563]] | b: -7.3991 | predicted value: [[0 0 0 1]] \n",
      "Iteration   545 | Cost: 0.0617 | W: [[4.82671329 4.82671329]] | b: -7.4254 | predicted value: [[0 0 0 1]] \n",
      "Iteration   550 | Cost: 0.0612 | W: [[4.84417701 4.84417701]] | b: -7.4514 | predicted value: [[0 0 0 1]] \n",
      "Iteration   555 | Cost: 0.0607 | W: [[4.86149907 4.86149907]] | b: -7.4772 | predicted value: [[0 0 0 1]] \n",
      "Iteration   560 | Cost: 0.0602 | W: [[4.8786817 4.8786817]] | b: -7.5028 | predicted value: [[0 0 0 1]] \n",
      "Iteration   565 | Cost: 0.0597 | W: [[4.89572708 4.89572708]] | b: -7.5283 | predicted value: [[0 0 0 1]] \n",
      "Iteration   570 | Cost: 0.0592 | W: [[4.91263734 4.91263734]] | b: -7.5535 | predicted value: [[0 0 0 1]] \n",
      "Iteration   575 | Cost: 0.0587 | W: [[4.92941455 4.92941455]] | b: -7.5785 | predicted value: [[0 0 0 1]] \n",
      "Iteration   580 | Cost: 0.0583 | W: [[4.94606075 4.94606075]] | b: -7.6033 | predicted value: [[0 0 0 1]] \n",
      "Iteration   585 | Cost: 0.0578 | W: [[4.96257792 4.96257792]] | b: -7.6279 | predicted value: [[0 0 0 1]] \n",
      "Iteration   590 | Cost: 0.0573 | W: [[4.97896799 4.97896799]] | b: -7.6524 | predicted value: [[0 0 0 1]] \n",
      "Iteration   595 | Cost: 0.0569 | W: [[4.99523288 4.99523288]] | b: -7.6766 | predicted value: [[0 0 0 1]] \n",
      "Iteration   600 | Cost: 0.0564 | W: [[5.01137443 5.01137443]] | b: -7.7007 | predicted value: [[0 0 0 1]] \n",
      "Iteration   605 | Cost: 0.0560 | W: [[5.02739446 5.02739446]] | b: -7.7246 | predicted value: [[0 0 0 1]] \n",
      "Iteration   610 | Cost: 0.0556 | W: [[5.04329474 5.04329474]] | b: -7.7483 | predicted value: [[0 0 0 1]] \n",
      "Iteration   615 | Cost: 0.0552 | W: [[5.05907701 5.05907701]] | b: -7.7719 | predicted value: [[0 0 0 1]] \n",
      "Iteration   620 | Cost: 0.0547 | W: [[5.07474297 5.07474297]] | b: -7.7952 | predicted value: [[0 0 0 1]] \n",
      "Iteration   625 | Cost: 0.0543 | W: [[5.09029429 5.09029429]] | b: -7.8184 | predicted value: [[0 0 0 1]] \n",
      "Iteration   630 | Cost: 0.0539 | W: [[5.10573259 5.10573259]] | b: -7.8415 | predicted value: [[0 0 0 1]] \n",
      "Iteration   635 | Cost: 0.0535 | W: [[5.12105948 5.12105948]] | b: -7.8644 | predicted value: [[0 0 0 1]] \n",
      "Iteration   640 | Cost: 0.0531 | W: [[5.1362765 5.1362765]] | b: -7.8871 | predicted value: [[0 0 0 1]] \n",
      "Iteration   645 | Cost: 0.0528 | W: [[5.15138518 5.15138518]] | b: -7.9096 | predicted value: [[0 0 0 1]] \n",
      "Iteration   650 | Cost: 0.0524 | W: [[5.16638704 5.16638704]] | b: -7.9320 | predicted value: [[0 0 0 1]] \n",
      "Iteration   655 | Cost: 0.0520 | W: [[5.18128353 5.18128353]] | b: -7.9542 | predicted value: [[0 0 0 1]] \n",
      "Iteration   660 | Cost: 0.0516 | W: [[5.19607609 5.19607609]] | b: -7.9763 | predicted value: [[0 0 0 1]] \n",
      "Iteration   665 | Cost: 0.0513 | W: [[5.21076612 5.21076612]] | b: -7.9982 | predicted value: [[0 0 0 1]] \n",
      "Iteration   670 | Cost: 0.0509 | W: [[5.22535502 5.22535502]] | b: -8.0200 | predicted value: [[0 0 0 1]] \n",
      "Iteration   675 | Cost: 0.0505 | W: [[5.23984413 5.23984413]] | b: -8.0416 | predicted value: [[0 0 0 1]] \n",
      "Iteration   680 | Cost: 0.0502 | W: [[5.25423478 5.25423478]] | b: -8.0631 | predicted value: [[0 0 0 1]] \n",
      "Iteration   685 | Cost: 0.0499 | W: [[5.26852826 5.26852826]] | b: -8.0844 | predicted value: [[0 0 0 1]] \n",
      "Iteration   690 | Cost: 0.0495 | W: [[5.28272586 5.28272586]] | b: -8.1056 | predicted value: [[0 0 0 1]] \n",
      "Iteration   695 | Cost: 0.0492 | W: [[5.29682881 5.29682881]] | b: -8.1267 | predicted value: [[0 0 0 1]] \n",
      "Iteration   700 | Cost: 0.0488 | W: [[5.31083836 5.31083836]] | b: -8.1476 | predicted value: [[0 0 0 1]] \n",
      "Iteration   705 | Cost: 0.0485 | W: [[5.3247557 5.3247557]] | b: -8.1684 | predicted value: [[0 0 0 1]] \n",
      "Iteration   710 | Cost: 0.0482 | W: [[5.33858201 5.33858201]] | b: -8.1890 | predicted value: [[0 0 0 1]] \n",
      "Iteration   715 | Cost: 0.0479 | W: [[5.35231845 5.35231845]] | b: -8.2095 | predicted value: [[0 0 0 1]] \n",
      "Iteration   720 | Cost: 0.0476 | W: [[5.36596615 5.36596615]] | b: -8.2299 | predicted value: [[0 0 0 1]] \n",
      "Iteration   725 | Cost: 0.0472 | W: [[5.37952623 5.37952623]] | b: -8.2502 | predicted value: [[0 0 0 1]] \n",
      "Iteration   730 | Cost: 0.0469 | W: [[5.39299978 5.39299978]] | b: -8.2703 | predicted value: [[0 0 0 1]] \n",
      "Iteration   735 | Cost: 0.0466 | W: [[5.40638788 5.40638788]] | b: -8.2903 | predicted value: [[0 0 0 1]] \n",
      "Iteration   740 | Cost: 0.0463 | W: [[5.41969158 5.41969158]] | b: -8.3101 | predicted value: [[0 0 0 1]] \n",
      "Iteration   745 | Cost: 0.0460 | W: [[5.43291191 5.43291191]] | b: -8.3299 | predicted value: [[0 0 0 1]] \n",
      "Iteration   750 | Cost: 0.0457 | W: [[5.4460499 5.4460499]] | b: -8.3495 | predicted value: [[0 0 0 1]] \n",
      "Iteration   755 | Cost: 0.0454 | W: [[5.45910653 5.45910653]] | b: -8.3690 | predicted value: [[0 0 0 1]] \n",
      "Iteration   760 | Cost: 0.0452 | W: [[5.4720828 5.4720828]] | b: -8.3884 | predicted value: [[0 0 0 1]] \n",
      "Iteration   765 | Cost: 0.0449 | W: [[5.48497965 5.48497965]] | b: -8.4076 | predicted value: [[0 0 0 1]] \n",
      "Iteration   770 | Cost: 0.0446 | W: [[5.49779804 5.49779804]] | b: -8.4268 | predicted value: [[0 0 0 1]] \n",
      "Iteration   775 | Cost: 0.0443 | W: [[5.5105389 5.5105389]] | b: -8.4458 | predicted value: [[0 0 0 1]] \n",
      "Iteration   780 | Cost: 0.0441 | W: [[5.52320314 5.52320314]] | b: -8.4647 | predicted value: [[0 0 0 1]] \n",
      "Iteration   785 | Cost: 0.0438 | W: [[5.53579165 5.53579165]] | b: -8.4835 | predicted value: [[0 0 0 1]] \n",
      "Iteration   790 | Cost: 0.0435 | W: [[5.54830532 5.54830532]] | b: -8.5022 | predicted value: [[0 0 0 1]] \n",
      "Iteration   795 | Cost: 0.0433 | W: [[5.56074502 5.56074502]] | b: -8.5208 | predicted value: [[0 0 0 1]] \n",
      "Iteration   800 | Cost: 0.0430 | W: [[5.57311159 5.57311159]] | b: -8.5393 | predicted value: [[0 0 0 1]] \n",
      "Iteration   805 | Cost: 0.0427 | W: [[5.58540587 5.58540587]] | b: -8.5577 | predicted value: [[0 0 0 1]] \n",
      "Iteration   810 | Cost: 0.0425 | W: [[5.59762868 5.59762868]] | b: -8.5759 | predicted value: [[0 0 0 1]] \n",
      "Iteration   815 | Cost: 0.0422 | W: [[5.60978084 5.60978084]] | b: -8.5941 | predicted value: [[0 0 0 1]] \n",
      "Iteration   820 | Cost: 0.0420 | W: [[5.62186314 5.62186314]] | b: -8.6121 | predicted value: [[0 0 0 1]] \n",
      "Iteration   825 | Cost: 0.0417 | W: [[5.63387636 5.63387636]] | b: -8.6301 | predicted value: [[0 0 0 1]] \n",
      "Iteration   830 | Cost: 0.0415 | W: [[5.64582128 5.64582128]] | b: -8.6479 | predicted value: [[0 0 0 1]] \n",
      "Iteration   835 | Cost: 0.0413 | W: [[5.65769863 5.65769863]] | b: -8.6657 | predicted value: [[0 0 0 1]] \n",
      "Iteration   840 | Cost: 0.0410 | W: [[5.66950919 5.66950919]] | b: -8.6833 | predicted value: [[0 0 0 1]] \n",
      "Iteration   845 | Cost: 0.0408 | W: [[5.68125366 5.68125366]] | b: -8.7009 | predicted value: [[0 0 0 1]] \n",
      "Iteration   850 | Cost: 0.0406 | W: [[5.69293278 5.69293278]] | b: -8.7183 | predicted value: [[0 0 0 1]] \n",
      "Iteration   855 | Cost: 0.0403 | W: [[5.70454726 5.70454726]] | b: -8.7357 | predicted value: [[0 0 0 1]] \n",
      "Iteration   860 | Cost: 0.0401 | W: [[5.71609779 5.71609779]] | b: -8.7529 | predicted value: [[0 0 0 1]] \n",
      "Iteration   865 | Cost: 0.0399 | W: [[5.72758505 5.72758505]] | b: -8.7701 | predicted value: [[0 0 0 1]] \n",
      "Iteration   870 | Cost: 0.0397 | W: [[5.73900973 5.73900973]] | b: -8.7872 | predicted value: [[0 0 0 1]] \n",
      "Iteration   875 | Cost: 0.0394 | W: [[5.75037248 5.75037248]] | b: -8.8042 | predicted value: [[0 0 0 1]] \n",
      "Iteration   880 | Cost: 0.0392 | W: [[5.76167397 5.76167397]] | b: -8.8211 | predicted value: [[0 0 0 1]] \n",
      "Iteration   885 | Cost: 0.0390 | W: [[5.77291483 5.77291483]] | b: -8.8379 | predicted value: [[0 0 0 1]] \n",
      "Iteration   890 | Cost: 0.0388 | W: [[5.7840957 5.7840957]] | b: -8.8546 | predicted value: [[0 0 0 1]] \n",
      "Iteration   895 | Cost: 0.0386 | W: [[5.79521721 5.79521721]] | b: -8.8712 | predicted value: [[0 0 0 1]] \n",
      "Iteration   900 | Cost: 0.0384 | W: [[5.80627997 5.80627997]] | b: -8.8877 | predicted value: [[0 0 0 1]] \n",
      "Iteration   905 | Cost: 0.0382 | W: [[5.81728458 5.81728458]] | b: -8.9042 | predicted value: [[0 0 0 1]] \n",
      "Iteration   910 | Cost: 0.0380 | W: [[5.82823164 5.82823164]] | b: -8.9205 | predicted value: [[0 0 0 1]] \n",
      "Iteration   915 | Cost: 0.0378 | W: [[5.83912175 5.83912175]] | b: -8.9368 | predicted value: [[0 0 0 1]] \n",
      "Iteration   920 | Cost: 0.0376 | W: [[5.84995547 5.84995547]] | b: -8.9530 | predicted value: [[0 0 0 1]] \n",
      "Iteration   925 | Cost: 0.0374 | W: [[5.86073337 5.86073337]] | b: -8.9691 | predicted value: [[0 0 0 1]] \n",
      "Iteration   930 | Cost: 0.0372 | W: [[5.87145603 5.87145603]] | b: -8.9851 | predicted value: [[0 0 0 1]] \n",
      "Iteration   935 | Cost: 0.0370 | W: [[5.88212398 5.88212398]] | b: -9.0011 | predicted value: [[0 0 0 1]] \n",
      "Iteration   940 | Cost: 0.0368 | W: [[5.89273778 5.89273778]] | b: -9.0170 | predicted value: [[0 0 0 1]] \n",
      "Iteration   945 | Cost: 0.0366 | W: [[5.90329796 5.90329796]] | b: -9.0327 | predicted value: [[0 0 0 1]] \n",
      "Iteration   950 | Cost: 0.0364 | W: [[5.91380505 5.91380505]] | b: -9.0485 | predicted value: [[0 0 0 1]] \n",
      "Iteration   955 | Cost: 0.0362 | W: [[5.92425957 5.92425957]] | b: -9.0641 | predicted value: [[0 0 0 1]] \n",
      "Iteration   960 | Cost: 0.0361 | W: [[5.93466204 5.93466204]] | b: -9.0796 | predicted value: [[0 0 0 1]] \n",
      "Iteration   965 | Cost: 0.0359 | W: [[5.94501296 5.94501296]] | b: -9.0951 | predicted value: [[0 0 0 1]] \n",
      "Iteration   970 | Cost: 0.0357 | W: [[5.95531283 5.95531283]] | b: -9.1105 | predicted value: [[0 0 0 1]] \n",
      "Iteration   975 | Cost: 0.0355 | W: [[5.96556214 5.96556214]] | b: -9.1258 | predicted value: [[0 0 0 1]] \n",
      "Iteration   980 | Cost: 0.0353 | W: [[5.97576138 5.97576138]] | b: -9.1411 | predicted value: [[0 0 0 1]] \n",
      "Iteration   985 | Cost: 0.0352 | W: [[5.98591102 5.98591102]] | b: -9.1563 | predicted value: [[0 0 0 1]] \n",
      "Iteration   990 | Cost: 0.0350 | W: [[5.99601154 5.99601154]] | b: -9.1714 | predicted value: [[0 0 0 1]] \n",
      "Iteration   995 | Cost: 0.0348 | W: [[6.0060634 6.0060634]] | b: -9.1864 | predicted value: [[0 0 0 1]] \n",
      "Iteration   999 | Cost: 0.0347 | W: [[6.01407016 6.01407016]] | b: -9.1984 | predicted value: [[0 0 0 1]] \n",
      "\n",
      "Final Predictions for AND gate:\n",
      "[[0 0 0 1]]\n",
      "\n",
      "Final Trained Weights: [[6.01407016 6.01407016]]\n",
      "Final Bias: -9.19836482803451\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "# Forward propagation\n",
    "def forward(X, W, b):\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A, Z\n",
    "\n",
    "# Compute cost \n",
    "def compute_cost(A, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = - (1/m) * np.sum(Y * np.log(A + 1e-8) + (1 - Y) * np.log(1 - A + 1e-8))\n",
    "    return cost\n",
    "\n",
    "# Backward propagation\n",
    "def backward(X, Y, A):\n",
    "    m = X.shape[1]\n",
    "    dZ = A - Y\n",
    "    dW = (1/m) * np.dot(dZ, X.T)\n",
    "    db = (1/m) * np.sum(dZ)\n",
    "    return dW, db\n",
    "\n",
    "# Parameter update\n",
    "def update_parameters(W, b, dW, db, learning_rate):\n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "    return W, b\n",
    "\n",
    "# Training loop with print details\n",
    "def train(X, Y, learning_rate=0.5, num_iterations=5000):\n",
    "    n_x = X.shape[0]\n",
    "    W = np.zeros((1, n_x))\n",
    "    b = 0\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Forward\n",
    "        A, Z = forward(X, W, b)\n",
    "        \n",
    "        # Cost\n",
    "        cost = compute_cost(A, Y)\n",
    "        \n",
    "        # Backward\n",
    "        dW, db = backward(X, Y, A)\n",
    "        \n",
    "        # Update\n",
    "        W, b = update_parameters(W, b, dW, db, learning_rate)\n",
    "\n",
    "        a = predict(X,W,b)\n",
    "        # Print at intervals\n",
    "        if i % 5 == 0 or i == num_iterations - 1:\n",
    "            print(f\"Iteration {i:5d} | Cost: {cost:.4f} | W: {W} | b: {b:.4f} | predicted value: {a} \")\n",
    "    \n",
    "    return W, b\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, W, b):\n",
    "    A, _ = forward(X, W, b)\n",
    "    return (A > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]])\n",
    "\n",
    "# Output labels\n",
    "Y = np.array([[0, 0, 0, 1]])\n",
    "\n",
    "# Train model\n",
    "W, b = train(X, Y, learning_rate=0.5, num_iterations=1000)\n",
    "\n",
    "# Predictions\n",
    "preds = predict(X, W, b)\n",
    "\n",
    "print(\"\\nFinal Predictions for AND gate:\")\n",
    "print(preds)\n",
    "print(\"\\nFinal Trained Weights:\", W)\n",
    "print(\"Final Bias:\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f813c73-ca81-46e3-a263-0057e57fb16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
